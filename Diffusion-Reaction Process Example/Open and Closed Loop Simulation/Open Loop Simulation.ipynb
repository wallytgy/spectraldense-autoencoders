{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Input, Activation, Dropout\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from deel.lip.layers import (\n",
    "    SpectralDense,\n",
    "    SpectralConv2D,\n",
    "    ScaledL2NormPooling2D,\n",
    "    FrobeniusDense,\n",
    ")\n",
    "from deel.lip.model import Sequential\n",
    "from deel.lip.activations import GroupSort, FullSort\n",
    "from Autoencoderclasses import Encoder, Decoder, DenseEncoder, DenseDecoder \n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from firstprinciples import diff_schemes\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.losses import MeanSquaredError \n",
    "import pandas as pd\n",
    "\n",
    "gamma = 4.0\n",
    "beta_T = 50.0\n",
    "beta_U = 2.0\n",
    "Delta = 0.8\n",
    "h_c = 0.002\n",
    "L = np.pi\n",
    "N_s = 45\n",
    "N_integration = int(Delta/h_c)\n",
    "delta_z = L/N_s\n",
    "testsize = 200\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "from pickle import load\n",
    "scaler_X = load(open('scaler_X.pkl', 'rb'))\n",
    "scaler_y = load(open('scaler_y.pkl', 'rb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "title = 'Dense 300 units 6 rd 1.0 noise'\n",
    "\n",
    "if title[0] == 'S':\n",
    "    encoder_and_decoder = tf.keras.models.load_model(title + \".h5\", custom_objects={'Encoder' : Encoder, 'Decoder' : Decoder})\n",
    "    def test_model_output(initial_state,u1,u2):\n",
    "        encoder = encoder_and_decoder.layers[0]\n",
    "        decoder = encoder_and_decoder.layers[1]\n",
    "        initial_state = initial_state.copy()\n",
    "        initial_state_normalized = scaler_X.transform([initial_state])\n",
    "        input = np.concatenate((encoder.call(np.array(initial_state_normalized).reshape((1,46))),np.array([u1/100.0,u2/100.0])), axis = None)\n",
    "        input = np.tile(input, (10,1))\n",
    "        RNN_model = tf.keras.models.load_model('RNN for ' + title + '.h5')\n",
    "        RNN_output = RNN_model.predict(input.reshape((1,10,8)),verbose = 0)\n",
    "        output = decoder.call(RNN_output)\n",
    "        return np.vstack((initial_state,scaler_X.inverse_transform(np.array(output))))\n",
    "else:\n",
    "    encoder_and_decoder = tf.keras.models.load_model(title + \".h5\", custom_objects={'DenseEncoder' : DenseEncoder, 'DenseDecoder' : DenseDecoder})\n",
    "    def test_model_output(initial_state,u1,u2):\n",
    "        encoder = encoder_and_decoder.layers[0]\n",
    "        decoder = encoder_and_decoder.layers[1]\n",
    "        initial_state = initial_state.copy()\n",
    "        initial_state_normalized = scaler_X.transform([initial_state])\n",
    "        input = np.concatenate((encoder.call(np.array(initial_state_normalized).reshape((1,46))),np.array([u1/100.0,u2/100.0])), axis = None)\n",
    "        input = np.tile(input, (10,1))\n",
    "        RNN_model = tf.keras.models.load_model('RNN for ' + title + '.h5')\n",
    "        RNN_output = RNN_model.predict(input.reshape((1,10,8)),verbose = 0)\n",
    "        output = decoder.call(RNN_output)\n",
    "        return np.vstack((initial_state,scaler_X.inverse_transform(np.array(output[0]))))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def firstprinciples_output(initial_state,u1,u2):\n",
    "    dim_x = 45\n",
    "    dim_t = 100\n",
    "    dt = 0.2/dim_t \n",
    "    dx = np.pi/dim_x\n",
    "    a = dt/dx**2\n",
    "    X_array = np.linspace(0,np.pi,(dim_x+1))\n",
    "    X_array = np.array(X_array)\n",
    "    T_array = np.linspace(0,0.2,dim_t+1)\n",
    "    res = diff_schemes(dt,dx,a,X_array,T_array,u1,u2,initial_state)\n",
    "    rfd = res.forward_diff_scheme()\n",
    "    output = rfd[::10]\n",
    "    return np.vstack((initial_state,np.array(output[1::])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_predict = test_model_output(np.array([6]*46),-100,-100)\n",
    "y_actual = firstprinciples_output(np.array([6]*46),-100,-100)\n",
    "\n",
    "x = np.linspace(0.0,np.pi ,46  )\n",
    "y = np.linspace(0, 0.2, 11)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.contour3D(X, Y, np.abs(y_predict-y_actual) , 50, cmap='plasma')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "error = mse(np.array(y_predict),np.array(y_actual)).numpy()\n",
    "print(\"Mean Squared Error\", error)\n",
    "\n",
    "df_y_predict = pd.DataFrame(y_predict)\n",
    "filepath = 'OpenLoop ' + title + '.xlsx'\n",
    "df_y_predict.to_excel(filepath, index=False)\n",
    "\n",
    "df_y_actual = pd.DataFrame(y_actual)\n",
    "filepath = 'OpenLoopActual.xlsx'\n",
    "df_y_actual.to_excel(filepath, index=False)\n",
    "\n",
    "\n",
    "df_y_error = pd.DataFrame(np.abs(y_predict-y_actual))\n",
    "filepath = 'OpenLoop ' + title + ' error.xlsx'\n",
    "df_y_error.to_excel(filepath, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
